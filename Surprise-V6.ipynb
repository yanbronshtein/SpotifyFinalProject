{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8681c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187273d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5bcfd",
   "metadata": {},
   "source": [
    "# Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450bad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/20 10:20:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "21/12/20 10:20:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/20 10:20:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, avg\n",
    "\n",
    "from pyspark.serializers import MarshalSerializer\n",
    "from pyspark.context import SparkContext\n",
    "sc = SparkContext(\"local\", \"serialization app\", serializer = MarshalSerializer())\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext is sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac504c9",
   "metadata": {},
   "source": [
    "# Initial Data Processing using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637c08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "df = pd.read_csv('./data/spotify_dataset.csv', on_bad_lines='skip')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c8457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('\"', '')\n",
    "df.columns = df.columns.str.replace('name', '')\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4b1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_artist(text):\n",
    "    text = (str(text)).lower()\n",
    "    FEAT_PAT = re.compile(r\"[\\s\\S]+[\\s]+(feat\\.|ft\\.|featuring|ft|feat)[\\s]+[\\s\\S]+\")\n",
    "    AMP_PAT = re.compile(r\"[\\s\\S]*(&|and|\\+)[\\s\\S]*\")\n",
    "    #check if we have featured artist\n",
    "    if FEAT_PAT.match(text):\n",
    "        text = re.split(r\"(feat\\.|ft\\.|featuring|ft|feat)\", text)[0]\n",
    "    \n",
    "    #Remove & from all artists\n",
    "    if AMP_PAT.match(text):\n",
    "        text = re.split(r\"&\", text)[0]\n",
    "    tok = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word = \" \".join(tok.tokenize(text))\n",
    "    text = unidecode(word)\n",
    "    w=\"\".join(text.split(\" \"))\n",
    "    text=w\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddda101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_artist'] = df['artist'].apply(clean_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a3833",
   "metadata": {},
   "source": [
    "**Save preprocessed dataframe to be processed in spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8704b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac1e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('./data/cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992184a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist= pd.unique(clean_df['clean_artist'].values.ravel())\n",
    "artist = pd.Series(np.arange(len(artist)), artist)\n",
    "clean_df[\"artist_id\"] = clean_df[['clean_artist']].applymap(artist.get)\n",
    "clean_df = clean_df[['user_id','artist_id', 'clean_artist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23c3108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69336433",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('./data/hugo_df.csv', index=False) #Save cleaned dataframe to hugo_df.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c32baa",
   "metadata": {},
   "source": [
    "# Working with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2278133",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv(\"./data/cleaned_df.csv\", header=True) #Read df processed in pandas as spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ac3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_as_spark = spark.read.csv('./data/spotify_dataset.csv', header=True) # get original dataset to get the track_name and playlist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f386cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+---------------+\n",
      "|             user_id|  \"artistname\"|         \"trackname\"| \"playlistname\"|\n",
      "+--------------------+--------------+--------------------+---------------+\n",
      "|9cc0cfd4d7d788510...|Elvis Costello|(The Angels Wanna...| HARD ROCK 2010|\n",
      "+--------------------+--------------+--------------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_df_as_spark.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc668f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_agg = spark_df.groupBy('user_id', 'clean_artist').agg(count('*')) #Get frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d07395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_agg=spark_df_agg.withColumnRenamed(\"count(1)\",\"freq\") #Rename aggregate column to freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03db2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_clean_df = spark.read.csv('./data/hugo_df.csv', header=True) #Contains user_id, artist_id, clean_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d4302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------+\n",
      "|             user_id|artist_id| clean_artist|\n",
      "+--------------------+---------+-------------+\n",
      "|9cc0cfd4d7d788510...|        0|elviscostello|\n",
      "|9cc0cfd4d7d788510...|        0|elviscostello|\n",
      "+--------------------+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_clean_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a90cc2",
   "metadata": {},
   "source": [
    "# Perform inner Join to get user_id, artist_id, clean_artist, and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0eaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = spark_df_agg.join(spark_clean_df, \n",
    "                                (spark_df_agg.clean_artist==spark_clean_df.clean_artist) & \\\n",
    "                                 (spark_df_agg.user_id==spark_clean_df.user_id),\n",
    "                                'inner').select(spark_df_agg.user_id, spark_df_agg.clean_artist, spark_df_agg.freq, spark_clean_df.artist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8046cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "combined_df.coalesce(1).write.csv('./data/combined_df.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c552b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(user_id,StringType,true),StructField( \"artistname\",StringType,true),StructField( \"trackname\",StringType,true),StructField( \"playlistname\",StringType,true)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df_as_spark.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7a3e7",
   "metadata": {},
   "source": [
    "# Get extra columns: track_name and playlist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d2208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'equalTo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j4/gvgvmhl12xn_0ml6mmbhnbfm0000gn/T/ipykernel_7497/1657763580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m spotify_final_spark_df = combined_df.join(original_df_as_spark,\n\u001b[0;32m----> 2\u001b[0;31m                                          \u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0moriginal_df_as_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                                                              \u001b[0moriginal_df_as_spark\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playlistname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                                              original_df_as_spark['trackname'])\n",
      "\u001b[0;32m~/opt/anaconda3/envs/music_env/lib/python3.8/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mnjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'equalTo'"
     ]
    }
   ],
   "source": [
    "spotify_final_spark_df = combined_df.join(original_df_as_spark,\n",
    "                                         (combined_df.user_id==original_df_as_spark.user_id),'inner').select(combined_df['user_id'],\n",
    "                                                                                                             combined_df['']\n",
    "                                                                                                             \n",
    "                                                                                                             original_df_as_spark['playlistname'],\n",
    "                                                                                                             original_df_as_spark['trackname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b0d03cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(user_id,StringType,true),StructField(clean_artist,StringType,true),StructField(freq,LongType,false),StructField(artist_id,StringType,true)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18064267",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_final_spark_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_final_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_final_spark_df.coalesce(1).write.csv('./data/spotify_final_spark_df.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72fe8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12855173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d9fe2",
   "metadata": {},
   "source": [
    "# 1).given user_id, return all of its songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "892b345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_artists(user_id):\n",
    "#     res = list(combined_df.filter(combined_df['user_id'] == user_id).select('clean_artist').toPandas()['clean_artist'])\n",
    "#     mvv_list = list(\n",
    "#         tableA.select('clean_artist').toPandas()['clean_artist']\n",
    "#     )\n",
    "    \n",
    "    combined_df.createOrReplaceTempView(\"hugo_table\") #Create view to run sql\n",
    "    res = spark.sql(f\"SELECT clean_artist from hugo_table where user_id='{user_id}';\").collect()\n",
    "     \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db661d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# res_list = [i.clean_artist for i in get_all_songs('00055176fea33f6e027cd3302289378b')]\n",
    "res_list = get_all_artists('00055176fea33f6e027cd3302289378b')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "deeabe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_artists = [list(i.asDict().values()) for i in res_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5910e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_artists = [item for sublist in my_artists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b2793ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auryn',\n",
       " 'bmike',\n",
       " 'thecatempire',\n",
       " 'thevamps',\n",
       " 'ollymurs',\n",
       " 'littlemix',\n",
       " 'austinmahone',\n",
       " 'blink182',\n",
       " 'beamiller',\n",
       " 'simpleplan',\n",
       " 'christinaperri',\n",
       " 'onerepublic',\n",
       " '5secondsofsummer',\n",
       " 'jakemiller',\n",
       " 'meghantrainor',\n",
       " 'jannikbrunke',\n",
       " 'thefray',\n",
       " 'beckyg',\n",
       " 'cimorelli',\n",
       " 'abigailbreslin',\n",
       " 'meghantonjes',\n",
       " 'markronson',\n",
       " 'alltimelow',\n",
       " 'againstthecurrent',\n",
       " 'highschoolmusicalcast',\n",
       " 'greenday',\n",
       " 'onedirection',\n",
       " 'avrillavigne',\n",
       " 'falloutboy',\n",
       " 'jack',\n",
       " 'taylorswift',\n",
       " 'gerardway',\n",
       " 'shawnmendes',\n",
       " 'jamesarthur',\n",
       " 'thewanted',\n",
       " 'nickjonas',\n",
       " 'panicatthedisco',\n",
       " 'maroon5',\n",
       " 'brunomars',\n",
       " 'the1975',\n",
       " 'edsheeran',\n",
       " 'imaginedragons',\n",
       " 'natalieimbruglia',\n",
       " 'charlixcx',\n",
       " 'demilovato']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0af835",
   "metadata": {},
   "source": [
    "# 2).given artist_id, return the corresponding unique artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38a281be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_artist(artist_id):\n",
    "    combined_df.createOrReplaceTempView(\"hugo_table\") #Create view to run sql\n",
    "    res = spark.sql(f\"SELECT clean_artist from hugo_table where artist_id='{artist_id}';\").collect()\n",
    "    return list(res[0].asDict().values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c172b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "x=get_unique_artist('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "963c3735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elviscostello'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa061f9c",
   "metadata": {},
   "source": [
    "# Get all artists for user 00055176fea33f6e027cd3302289378b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece41da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop() #Run last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26da2b5",
   "metadata": {},
   "source": [
    "# Scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d050724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13b3ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pandas_df = combined_df.write.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pandas_df = combined_df.write.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2f66769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "combined_df.coalesce(1).write.csv('./data/combined_pandas_df.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6078772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pandas_df = pd.read_csv('./data/combined_pandas_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8708bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>clean_artist</th>\n",
       "      <th>freq</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00055176fea33f6e027cd3302289378b</td>\n",
       "      <td>5secondsofsummer</td>\n",
       "      <td>1.010762</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00055176fea33f6e027cd3302289378b</td>\n",
       "      <td>5secondsofsummer</td>\n",
       "      <td>1.010762</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00055176fea33f6e027cd3302289378b</td>\n",
       "      <td>5secondsofsummer</td>\n",
       "      <td>1.010762</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00055176fea33f6e027cd3302289378b</td>\n",
       "      <td>5secondsofsummer</td>\n",
       "      <td>1.010762</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00055176fea33f6e027cd3302289378b</td>\n",
       "      <td>5secondsofsummer</td>\n",
       "      <td>1.010762</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id      clean_artist      freq  artist_id\n",
       "0  00055176fea33f6e027cd3302289378b  5secondsofsummer  1.010762        707\n",
       "1  00055176fea33f6e027cd3302289378b  5secondsofsummer  1.010762        707\n",
       "2  00055176fea33f6e027cd3302289378b  5secondsofsummer  1.010762        707\n",
       "3  00055176fea33f6e027cd3302289378b  5secondsofsummer  1.010762        707\n",
       "4  00055176fea33f6e027cd3302289378b  5secondsofsummer  1.010762        707"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pandas_df[[\"freq\"]] = scaler.fit_transform(combined_pandas_df[[\"freq\"]])\n",
    "combined_pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f6403b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc7eedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(combined_pandas_df[['user_id', 'artist_id', 'freq']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f3a08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fb711",
   "metadata": {},
   "source": [
    "# Training with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83fd794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testset_accuracy(testset):\n",
    "    total_matches = 0\n",
    "    for item in testset:\n",
    "        uid = item[0]\n",
    "        preds = []\n",
    "        for id in combined_pandas_df.artist_id.values:\n",
    "            preds.append(svd.predict(uid=uid, iid=id))\n",
    "        iid=[]\n",
    "        for pred in preds:\n",
    "            iid.append(pred.iid)\n",
    "        iid=list(dict.fromkeys(iid))\n",
    "        predicted_artists = set()\n",
    "        for i in iid[:30]: #Compare top 30 recommendations\n",
    "#             artist = artist_df.loc[artist_df.artist_id == i].artist.values[0]\n",
    "            artist = get_unique_artist(artist_id=i)\n",
    "            predicted_artists.add(artist)\n",
    "#         known_artists = list(set(df.loc[df[\"user_id\"] == uid].artist.values))\n",
    "        known_artist = get_all_artists(user_id=uid)\n",
    "        #print(len(known_artists))\n",
    "        total_matches += len(predicted_artists.intersection(known_artists))\n",
    "    print(total_matches / (30 * len(testset)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2cfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 122:=============================================>           (4 + 1) / 5]\r"
     ]
    }
   ],
   "source": [
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=2)\n",
    "svd = SVD(n_epochs=1, verbose=True)\n",
    "for trainset, testset in kf.split(data):\n",
    "    # train and test algorithm.\n",
    "    svd.fit(trainset)\n",
    "    get_testset_accuracy(testset[:2])\n",
    "    predictions = svd.test(testset)\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_songs(artist, num_songs = 5):\n",
    "    return list(combined_pandas_df[combined_pandas_df['cleaned_artist'] == artist]['track'].value_counts()[0:num_songs].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc28d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation():\n",
    "    res = {}\n",
    "    for i in iid[:5]:\n",
    "        artist = combined_pandas_df.loc[combined_pandas_df.artist_id == i].cleaned_artist.values[0]\n",
    "        res[artist] = get_top_songs(artist)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529bd1b",
   "metadata": {},
   "source": [
    "# Let's get the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ce2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
